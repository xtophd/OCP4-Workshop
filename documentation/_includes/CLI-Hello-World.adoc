:sectnums:
:sectnumlevels: 2
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

:toc:
:toclevels: 1

= CLI: Hello World

[discrete]
== Preface

A "Hello, World!" program is traditionally used to illustrate the basic syntax of a programming language.  The program merely outputs or displays "Hello, World!" to a user. Due to it's simplicity in nature, it is often the very first program people write when learning a new language or platform.

These exercises will step through everything needed to bring a "Hello, World!" program online in our Openshift Container Platform.  We are going to do it several different ways to illustrate some best and worst practices of container usage.

There are 6 fundamental steps to deploying an application in the Openshift Container Platform:

  . *Credentials:* oc login
  . *Create a Project:* oc new project 
  . *Deploy an Image:* oc new-app
  . *Expose a Route:* oc expose
  . *Modify the Project, Build or Deployment*
  . *Validation*
  
NOTE: Arguably, in a production environment step-5 (making modifications) would normally be done before step-4 (exposing a route).  However, the end result is the same and it helps the repeatable consistancy of these exercises to just do things in this order.

== My First Application

  === Sign-on as admin

You may have already established a session in the "CLI: First Time Login".  Never the less, here are the condensed instructions again.

Connect to the *bastion* as the *root* user.

.[root@workstation ~]#
----
ssh root@bastion.example.com
----

Now sign-on to Openshift with username `kubeadmin`.  This is easily accomplished by running the *workshop-kubeadmin.sh* script

.[root@master ~]#
----
workshop-kubeadmin.sh
----

Ensure that you are using the *default* project

.[root@master ~]#
----
oc project default
----

=== Create a Project

We begin by creating a *Project*.

.[root@master ~]#
----
oc new-project exercise-hello-world1 --description="Hello World exercise" --display-name="Exercise: Hello-World-1"

oc get projects
----

.Your output should look like this
[source,indent=4]
----
NAME                                               DISPLAY NAME              STATUS
default                                                                      Active
exercise-hello-world1                              Exercise: Hello-World-1   Active
kube-node-lease                                                              Active
kube-public                                                                  Active
kube-system                                                                  Active
openshift                                                                    Active
openshift-apiserver                                                          Active
...<SNIP>...
----

You can also use `oc projects` to get a list of projects along with a convenient asterisk indicating the current active project.

.[root@master ~]#
----
oc projects
----

.Your output should look like this
[source,indent=4]
----
You have access to the following projects and can switch between them with ' project <proje
ctname>':

    default
  * exercise-hello-world1 - Exercise: Hello-World-1
    kube-node-lease
    kube-public
    kube-system
    openshift
    openshift-apiserver
...<SNIP>...

Using project "exercise-hello-world1" on server "https://master.example.com:8443".
----

We can gather some more information about our new *Project* using `oc describe project`

.[root@master ~]#
----    
oc describe project exercise-hello-world1
----  

.Your output should look like this
[source,indent=4]
----
Name:                   exercise-hello-world1
Created:                2 minutes ago
Labels:                 kubernetes.io/metadata.name=exercise-hello-world1
Annotations:            openshift.io/description=Hello World exercise
                        openshift.io/display-name=Exercise: Hello-World-1
                        openshift.io/requester=system:admin
                        openshift.io/sa.scc.mcs=s0:c29,c19
                        openshift.io/sa.scc.supplemental-groups=1000850000/10000
                        openshift.io/sa.scc.uid-range=1000850000/10000
Display Name:           Exercise: Hello-World-1
Description:            Hello World exercise
Status:                 Active
Node Selector:          <none>
Quota:                  <none>
Resource limits:        <none>
----

=== Deploy an Image

We are not quite ready to start building our own container images from scratch, so we will leverage an existing one available from the Red Hat's Container Catalog.

.[root@master ~]#
----
oc new-app registry.access.redhat.com/rhscl/httpd-24-rhel7 --name=hello-app1
----

You just instructed Openshift to create a new application called *hello-app1*.  Without getting caught up in the details, basically what happens is:

  * Openshift checks the local catalog for an existing copy of the specified image *httpd-24-rhel7*
  * Since this is our first deployment in Openshift, the image was likely not available and so Openshift automatically fetches it from the Red Hat Container Catalog and adds it to the local catalog
  * A *Container Creating Container* is initiated to contruct the desired image (ie: customizations or source integration)
  * A *Deployment Container* is initiated to launch the desired image
  * and Voi La!!! The container is deployed and ready to go to work.

Now let's have a closer inspection with a couple different commands.  

.[root@master ~]#
----
oc status

oc get deployment
    
oc get pods
    
oc get services
----

The IP address shown for the service is the internal non-routable network for the pod.  From any node in the cluster, we can test the pod for application functionality before exposing the service to the public. 

Run `oc get pods` and `oc get services` several times to watch the changes as described above.

.Your output should look like this
[source,indent=4]
----
In project Exercise: Hello-World-1 (exercise-hello-world1) on server https://api.ocp4ov10g.example.com:6443

svc/hello-app1 - 172.30.148.27 ports 8080, 8443
  deployment/hello-app1 deploys istag/hello-app1:latest
    deployment #2 running for 1 second - 1 pod
    deployment #1 deployed 2 seconds ago

NAME         READY   UP-TO-DATE   AVAILABLE   AGE
hello-app1   1/1     1            1           72s

NAME                          READY   STATUS    RESTARTS   AGE
hello-app1-5749464997-tfckj   1/1     Running   0          95s

NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE
hello-app1   ClusterIP   172.30.148.27   <none>        8080/TCP,8443/TCP   107s
----

We can also monitor the deployment of the application by running `oc rollout status`.  This command will exit once the deployment has completed and the web application is ready.

.[root@master ~]#
----
oc rollout status deployment/hello-app1
----

Once **hello-app1-????** is in a 'Running' state, you can proceed with verification that the POD is operating correctly.  There are a few scripts installed in /usr/local/bin to make these steps a little less error prone.  The native commands are also provided below.

.[root@master ~]#
----
workshop-validate-service.sh
----

[NOTE]
====
_Native command(s) to verify POD service_
----
oc get services

curl http://{ip_address}}:8080
----
====

This illustrates that the application is alive and providing output as expected.  However, it is not yet exposed to the outside world.  For this, we need to create a 'route'.

=== Expose a Route

In Openshift, routers are the processes responsible for making services accessible to the outside world.  Routers run as containers on nodes.  Therefore, the nodes where routers run must be reachable themselves.

Let's create a route for our new application.

.[root@bastion ~]#
----
oc expose service hello-app1
----

You can retrieve the current list of configured routes with the `oc get routes` command.

.[root@bastion ~]#
----
oc get routes
----

.Your output should look like this
[source,indent=4]
----
NAME         HOST/PORT                                                PATH   SERVICES    PORT       TERMINATION   WILDCARD
hello-app1   hello-app1-helloworld1.apps.CLUSTERNAME.example.com            hello-app1  8080-tcp                 None
----

[discrete]
=== Interim Validation

Again, there are a few scripts installed in /usr/local/bin to make these steps a little less error prone.  The native commands are also provided below.

.[root@master ~]#
----
workshop-validate-app.sh
----

The output from the above command will result in a full dump of the HTML test page configured by the default httpd package installation.  Let's run the command again and be a little more specific so we can verify a functional httpd server.  

.[root@master ~]#
----
workshop-validate-app.sh | grep "Test Page"
----

.Your output should look like this
[source,indent=4]
----
<title>Test Page for the Apache HTTP Server on Red Hat Enterprise Linux</title>
<h1>Red Hat Enterprise Linux <strong>Test Page</strong></h1>
----

[discrete]
=== Exploring the Container

Now we will take a moment to poke around the container namespace.  We need the pods full name in order to connect to a shell within the container.

Once again, there is a sample script to easily connect to the POD's shell.

.[root@master ~]#
----
workshop-rsh.sh
----

[NOTE]
====
_Native command(s) to rsh to POD_
----
oc get pods

oc rsh {{ POD NAME }}
----
====

Now that you have connected to the active container, have a look around


.sh-4.2$
----
id
----

.Your output should look like this
[source,indent=4]
----
uid=1000120000 gid=0(root) groups=0(root),1000120000
----

.sh-4.2$
----
ps -ef
----
    
.Your output should look like this
[source,indent=4]
----
UID         PID   PPID  C STIME TTY          TIME CMD
1000120+      1      0  0 14:26 ?        00:00:03 httpd -D FOREGROUND
1000120+     24      1  0 14:26 ?        00:00:00 /usr/bin/cat
1000120+     25      1  0 14:26 ?        00:00:00 /usr/bin/cat
1000120+     26      1  0 14:26 ?        00:00:00 /usr/bin/cat
1000120+     27      1  0 14:26 ?        00:00:00 /usr/bin/cat
1000120+     28      1  0 14:26 ?        00:00:18 httpd -D FOREGROUND
1000120+     29      1  0 14:26 ?        00:00:18 httpd -D FOREGROUND
1000120+     31      1  0 14:26 ?        00:00:18 httpd -D FOREGROUND
1000120+     35      1  0 14:26 ?        00:00:18 httpd -D FOREGROUND
1000120+     37      1  0 14:26 ?        00:00:18 httpd -D FOREGROUND
1000120+     74      0  0 17:50 ?        00:00:00 /bin/sh
1000120+     84     74  0 17:50 ?        00:00:00 ps -ef
----

Normally files serverd by httpd go into /var/www/html, but the security-conscious random uid does not have permissions to write to this directory (or any other directory than the tmp dirs).

.sh-4.2$
----
cd /var/www/
    
ls -la

echo "Can I create a file" > testfile
----

.Your output should look like this
[source,indent=4]
----
total 0
drwxr-xr-x.  4 default root  33 Jul 17 17:12 .
drwxr-xr-x. 19 root    root 249 Jul 17 17:13 ..
drwxr-xr-x.  2 default root   6 May  9 13:18 cgi-bin
drwxr-xr-x.  2 default root   6 May  9 13:18 html

sh: testfile: Permission denied
----


The primary thing we are trying to point out here is that the UID the process is running with (ie: **1000120000**) does not have permissions to write to any part of the container filesystem except traditionally open directories like **/tmp** or **/var/tmp**.  Next, you will do a series of exercises detailing how to make adjustments to the project and deploy a real helloworld application.

When you are done exploring the container namespace, exit the shell and return to command-line of master.example.com


.sh-4.2$
----
exit
----

=== Modify the Project, Build or Deployment

For our first solution, we are going to adjust the current project's security attribute to enable some minor modifications to a deployed pod.  We begin by editing the *namespace attributes* of the *helloworld* project.
First let's have a look at the current settings.
    
.[root@master ~]#
----
oc describe namespace exercise-hello-world1
----


.Your output should look like this
[source,indent=4]
----
Name:         exercise-hello-world1
Labels:       kubernetes.io/metadata.name=exercise-hello-world1
Annotations:  openshift.io/description: Hello World exercise
              openshift.io/display-name: Exercise: Hello-World-1
              openshift.io/requester: system:admin
              openshift.io/sa.scc.mcs: s0:c25,c15
              openshift.io/sa.scc.supplemental-groups: 1000630000/10000
              openshift.io/sa.scc.uid-range: 1000630000/10000
Status:       Active

No resource quota.

No LimitRange resource.
----

Now let us reconfigure the UID range openshift will use to deploy the container.

.[root@master ~]#
----
exercise1-patch-scc.sh
----

[NOTE]
====
_Native command(s) to patch namespace security annotation_
----
oc patch namespace helloworld1 --patch '{"metadata":{"annotations":{"openshift.io/sa.scc.uid-range":"1001/10000"}}}'
----
====

[NOTE]
====
_Alternate method to edit security annotations_
----
oc edit namespace helloworld
----
Adjust the following attribute: "openshift.io/sa.scc.uid-range: 1001/10000"

Save and Exit
====        

Now we will use 'oc delete' to redeploy a fresh instance of our hello-app pod.

.[root@master ~]#
----
oc delete --all pods -n helloworld

watch oc get pods
----

Depending on how quickly you run *oc get pods* after rolling out the new deployment, you may see the ContainerCreating container running and/or the pre-existing deployment of *hello-app-1-????* terminating.  Also note that the 'oc' command has a built in 'watch mode', although I prefer the refreshed output provided by the linux *watch* command.  Either way, just press CTRL-C to exit either `watch` modes and return to your shell.

[NOTE]
====
_Using the native watch mode for oc_
----
oc get pods -w
----
====

After rolling out the new pod kubernetes will (by default) shutoff and remove older 
versions of the pod.

.Your output should look like this
[source,indent=4]
----
NAME                READY     STATUS        RESTARTS   AGE                                   
hello-app-1-wbq42   0/1       Terminating   0          2h                                    
hello-app-2-lhvgp   1/1       Running       0          10s
----


Next we will once again connect to the containers shell and explore the changes that were implemented by editing the security attributes.

.[root@master ~]#
----
workshop-rsh-pod.sh
----

Now that you are back in the container namespace, have a look at the /var/www/html directory and see if you notice something different.

.sh-4.2$
----
id
----

.Your output should look like this
[source,indent=4]
----
uid=1001(default) gid=0(root) groups=0(root),1000120000
----

.sh-4.2$
----
cd /var/www
ls -la
----

.Your output should look like this
[source,indent=4]
----
total 0
drwxr-xr-x.  4 default root  33 Jul 17 17:12 .
drwxr-xr-x. 19 root    root 249 Jul 17 17:13 ..
drwxr-xr-x.  2 default root   6 May  9 13:18 cgi-bin
drwxr-xr-x.  2 default root   6 May  9 13:18 html
----

.sh-4.2$
----
exit
----


To save time and avoid the complexity of editing an HTML file, we will just copy an exist file into the running container.

You can use the sample script in /var/tmp to make life a little easier.

.[root@master ~]#
----
exercise1-install-helloworld.sh
----

.Your output should look like this
[source,indent=4]
----
DETERMINED POD = hello-app-2-qvsl8
BASH EXEC: oc cp /usr/local/etc/exercise-hello-world.html hello-app-2-qvsl8:/var/www/html/index.html

Copying /var/tmp/helloworld.html to hello-app-2-qvs18:/var/www/html/index.html
----

[NOTE]
====
_Native command(s) to copy index.html to POD_
----
oc get pods

oc cp /var/tmp/helloworld.html {{ POD NAME }}:/var/www/html/index.html
----
====

=== Validation

There is a sample script in /var/tmp to make life a little easier.

.[root@master ~]#
----
workshop-validate-app.sh
----

.Your output should look like this
[source,indent=4]
----
DETERMINED ROUTE: helloworld.cloud.example.com
EXEC: curl helloworld.cloud.example.com

<html>
<body>
Hello, World!
</body>
</html>
----

[NOTE]
====
_Native command(s) to validate application_
----    
curl http://helloworld.cloud.example.com
----
====

IMPORTANT: The solution you just completed is NOT a recommended solution on how to deploy a container for production use.  This solution was provided to touch on a few concepts unique to the Openshift Container Platform.  Take some time to review: container design, project attributes, process uid/gid (ie: namespaces) in a containerized environment, filesystems, etc...

TIP: The official method to allow processes in an Openshift application to use specific user-IDs is to configure a "Service Account" with appropriate SCCs for the project.  There are more advanced exercises planned for this workshop which will include this type of configuration, but for now if you are interested in a summarised blog on the topic please read: link:https://blog.openshift.com/understanding-service-accounts-sccs/[Understanding Service Accounts and SCCs]


// -------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------

== Hello World II : Use emptyDir

In this solution, instead of changing the project's security attributes to allow write access to /var/www/html we are going to mount a volume (ie: filesystem) which provides sufficient read/write permissions for the defacto process UID.  The type of volume we will be using is called an *emptyDir*.

For real world use cases, *emptyDir* is often used as a local cache. Since the backing store for emptyDir comes from the local host it is often more performant than network base storage.

Although we are not technically using is for cache, *emptyDir* suits our needs so let’s proceed to deploy and configure the pod to mount an *emptyDir* volume under /var/www/html.

We begin this solution by repeating the steps to deploy a httpd base image.

=== Create a Project

.[root@master ~]#
----
oc new-project helloworld2 --description="My Second OCP App" --display-name="Hello World II"
----

=== Deploy an Image

.[root@master ~]#
----    
oc new-app registry.access.redhat.com/rhscl/httpd-24-rhel7 --name=hello-app2
----

=== Expose a Route

.[root@master ~]#
----
oc expose service hello-app2
----

=== Modify the Project, Build or Deployment

.[root@master ~]#
----
oc set volume deployment/hello-app2 --add --mount-path /var/www/html --type emptyDir
----

Use the following command to track the status of your deployment.

.[root@master ~]#
----    
oc rollout status deployment/hello-app2
----

NOTE: You will need to wait until the pod is finished being deployed until you can inject a custom HTML file into the container image.

.Your output should look like this
[source,indent=4]
----
Waiting for rollout to finish: 0 of 1 updated replicas are available...                      
Waiting for latest deployment config spec to be observed by the controller loop...           
replication controller "hello-app2-2" successfully rolled out 
----

Now you can proceed with customizing the deployed (and live) pod.

Once again, you can use the sample script in /var/tmp to make life a little easier.

.[root@master ~]#
----
workshop-install-helloworld.sh
----

.Your output should look like this
[source,indent=4]
----
DETERMINED POD = hello-app2-2-92cwr
BASH EXEC: oc cp /var/tmp/helloworld.html hello-app2-2-92cwr:/var/www/html/index.html

Copying /var/tmp/helloworld.html to hello-app2-2-92cwr:/var/www/html/index.html
----

=== Validation

.[root@master ~]#
----
workshop-validate-app.sh
----

.Your output should look like this
[source,indent=4]
----
DETERMINED ROUTE: helloworld2.cloud.example.com
EXEC: curl helloworld2.cloud.example.com

<html>
<body>
Hello, World!
</body>
</html>
----

If you happen to rsh into the container namespace, have a look at the permissions of /var/www/html.  You will notice that it matches the process uid.  Although it is not considered a best practice to inject files into a container during runtime, this method has it's niche use cases.

TIP: Why does the POD version start with '2' this time instead of '1'?

TIP: What would happen if this app were to be scaled up?  Would new PODs contain our helloworld HTML?

NOTE: Important to note that any filesystems mounted with emptyDir is non-persistant and will be destoyed when the container is stopped.

// -------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------

== Hello-World III : Use NFS

The purpose of this unit is not to boil the ocean with "Hello, World!".  Rather we are trying to provide basic principals of how a container functions.  So with that in mind, our next solution will be to utilize some network storage (ie: NFS) to provide the common source for our helloworld web server.

During the pre-installation phase of this lab, the host workshop.example.com was configured with an NFS server and an export called /exports/helloworld.  Let's simply mount that within the container to demonstrate our "Hello, World!" again.

=== Create a Project

.[root@master ~]#
----
oc new-project helloworld3 --description="My Third OCP App" --display-name="Hello World III"
----

=== Deploy an Image

.[root@master ~]#
----
oc new-app registry.access.redhat.com/rhscl/httpd-24-rhel7 --name=hello-app3
----

=== Expose a Route

.[root@master ~]#
----    
oc expose service hello-app3
----

=== Modify the Project, Build or Deployment

Now it is time to define our persistent storage parameters for out application deployment.  The Workstation host in your OCP workshop has been configured with an NFS server that is already exporting helloworld HTML.  The only goal here is to mount that volume at /var/www/html within our POD.

There is a more thorough explination of storage in the WebUI portion of this workshop, so for now let's avoid technical talk and just go through the motion.

==== Create a PV (Persistent Volume)

.[root@master ~]#
----    
oc create -f /usr/local/etc/exercise-hello-world-pv.yaml
----

.Your output should look like this
[source,indent=4]
----
persistentvolume/hello-world created
----

.[root@master ~]#
----
oc get pv
----

.Your output should look like this
[source,indent=4]
----
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM     STORAGECLASS   REASON    AGE
hello-world 5Gi        RWX            Retain           Available                                      7s
----

==== Create a PVC (Persistent Volume Claim)

Now create the persistent volume claim. 

.[root@master ~]#
----
oc create -f /usr/local/etc/exercise-hello-world-pvc.yaml
----

.Your output should look like this
[source,indent=4]
----
persistentvolumeclaim/hello-world-claim created
----

==== Check Storage Status

Next check the status of the pv and pvc.  You should see that the STATUS of the pv has changed to *Bound* and the CLAIM is held by *helloworld3/helloworld-claim*.  Likewise, the pvc will show a STATUS of *Bound* to the VOLUME *cli-hello3*

.[root@master ~]#
----
oc get pv

oc get pvc
----

.Your output should look like this
[source,indent=4]
----
NAME         CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                        STORAGECLASS   REASON    AGE
cli-hello3   5Gi        RWX            Retain           Bound     helloworld3/cli-hello3-claim                         11m

NAME              STATUS    VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE
cli-hello-claim   Bound     cli-hello3  5Gi        RWX                           58s
----

==== Modify the Deployment Config

Now that the storage prep work is complete, it is time to modify the deployment configuration with the storage information.

.[root@master ~]#
----
oc set volume deployment/hello-app3 --add --mount-path /var/www/html --type persistentVolumeClaim --claim-name=cli-hello3-claim

oc rollout status deployment/hello-app3
----

NOTE: You will need to wait until the pod is deployed before you can validate the application.

=== Validation

.[root@master ~]#
----
cheat-validate-app.sh
----

.Your output should look like this
[source,indent=4]
----
DETERMINED ROUTE: helloworld3.cloud.example.com
EXEC: curl helloworld3.cloud.example.com

<html>
<body>
Hello, World!
</body>
</html>
----

// -------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------

== Hello-World IV : Use Source Control (git)

Next we will implement the ideal solution.  Using a source code repository we will initiate a container deployment which will pull the source code and layer it into a base container (ie: source to images / S2I) and deploy it as a single unified image.

=== Create a Project

.[root@master ~]#
----
oc new-project helloworld4 --description="My Fourth OCP App" --display-name="Hello World IV"   
----

=== Deploy an Image

.[root@master ~]#
----  
oc new-app registry.access.redhat.com/rhscl/httpd-24-rhel7~https://github.com/xtophd/OCP-Workshop --context-dir=/src/helloworld --name=hello-app
    
oc logs -f bc/hello-app
----

.Your output should look like this
[source,indent=4]
----
Cloning "https://github.com/xtophd/OCP-Workshop" ...
        Commit: eeec609783b7b233120e34f0410e2acdbc0029f6 (Update CLI-Hello-World.adoc)
        Author: Christoph Doerbeck <38790538+xtophd@users.noreply.github.com>
        Date:   Thu Aug 16 12:37:23 2018 -0500
---> Enabling s2i support in httpd24 image
AllowOverride All
---> Installing application source
=> sourcing 20-copy-config.sh ...
=> sourcing 40-ssl-certs.sh ...
Pushing image docker-registry.default.svc:5000/helloworld4/hello-app4:latest ...
Pushed 1/5 layers, 22% complete
Pushed 2/5 layers, 42% complete
Pushed 3/5 layers, 65% complete
Pushed 4/5 layers, 88% complete
Pushed 4/5 layers, 100% complete
Pushed 5/5 layers, 100% complete
Push successful
----

A couple more commands to help inspect the status of our application deployment

.[root@master ~]#
----  
oc get events

oc rollout status dc/hello-app4
----

=== Expose a Route

Now we can run a few more commands to increase our familiarity with deployment process

.[root@master ~]#
----
oc expose service hello-app
----

=== Modify the Project, Build or Deployment

In this deployment model, there is no post-modifications we need to make to the deployment configuration.

=== Validation

.[root@master ~]#
----
workshop-validate-app.sh
----

.Your output should look like this
[source,indent=4]
----
DETERMINED ROUTE: hello-app-helloworld4.cloud.example.com
EXEC: curl hello-app-helloworld4.cloud.example.com

<html>
<body>
Hello, World!
</body>
</html>
----

// -------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------

== Hello-World V : Use Dockerfile

Next we will implement another solution using a Dockerfile.  Again, using a source code repository we initiate a container deployment but this time we only specify a `Dockerfile` source.

To mix things up a little, we will also use a PHP enhanced container image instead of the plain httpd image we have been using.  The dockerfile in the source repository looks something like this:

.sample dockerfile
[source,indent=4]
----
##
## Parameters required to work with a RHSCL image designed for S2I
##
FROM registry.access.redhat.com/rhscl/php-71-rhel7
MAINTAINER Joe Foo jfoo@example.com
USER 0
COPY index.php /tmp/src/
RUN /usr/libexec/s2i/assemble
CMD /usr/libexec/s2i/run
Expose 8080
----

=== Create a Project

.[root@master ~]#
----
oc new-project helloworld5 --description="My Fifth OCP App" --display-name="Hello World V"   
----

=== Deploy an Image

.[root@master ~]#
----
oc new-app https://github.com/xtophd/OCP-Workshop --context-dir=/src/dockerfile --name=hello-app
    
oc logs -f bc/hello-app

oc rollout status dc/hello-app5
----

=== Expose a Route

.[root@master ~]#
----
oc expose service hello-app
----

=== Modify the Project, Build or Deployment

In this deployment model, there is no post-modifications we need to make to the deployment configuration.

=== Validation

.[root@master ~]#
----
workshop-validate-app.sh
----

.Your output should look like this
[source,indent=4]
----
DETERMINED ROUTE: hello-app-helloworld5.cloud.example.com
EXEC: curl hello-app-helloworld5.cloud.example.com

<html>
<body>
Hello, World!
</body>
</html>
----


== Clean Up (Informational Only)

NOTE: We provide the commands needed for general cleanup as information only.  You can safely skip this section if you want to save some time.

The speed things up, cleanup for all of the work done above is accomplished with a script.

.[root@master ~]#
----
exercise6-cleanup.sh
----

If you want to explore all of the commands involed, you can use the examples below to cleanup the various namespaces and storage configs.

.[root@master ~]#
----
oc project default
    
oc delete project helloworld1
    
oc delete project helloworld2
    
oc delete project helloworld3
    
oc delete project helloworld4

oc delete project helloworld5

oc delete pv hello-world

oc get pods --all-namespaces -o wide
----

[discrete]
== End of Unit

*Next:* link:WebUI-First-Time-Login.adoc[OCP WebUI: First Time Login]

link:../OCP-Workshop.adoc#toc[Return to TOC]

////
Always end files with a blank line to avoid include problems.
////
